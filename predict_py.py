# -*- coding: utf-8 -*-
"""predict.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MEpVsBngsQvvfByTKGgNEJEZgigbZ8Sc
"""

import numpy as np
import librosa
from tensorflow.keras.models import load_model
import os
!wget -q https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip
!unzip -oq Audio_Speech_Actors_01-24.zip -d ravdess_data

def live_inference(audio_path, model_path="emotion_model.keras"):


    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model file not found: {model_path}")


    model = load_model(model_path)


    y, sr = librosa.load(audio_path, sr=22050)
    y, _ = librosa.effects.trim(y)


    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)
    log_mel = librosa.power_to_db(mel)

    if log_mel.shape[1] < 128:
        log_mel = np.pad(log_mel, pad_width=((0, 0), (0, 128 - log_mel.shape[1])), mode="constant")
    else:
        log_mel = log_mel[:, :128]


    X = log_mel.reshape(1, 128, 128, 1)


    prediction = model.predict(X, verbose=0)


    emotions = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']
    emotion_index = np.argmax(prediction)
    confidence = float(np.max(prediction) * 100)

    return emotions[emotion_index], confidence


test_audio = "ravdess_data/Actor_01/03-01-01-01-01-01-01.wav"

try:
    print("Running inference...")
    emotion, conf = live_inference(test_audio, model_path="emotion_model.keras")

    print("="*30)
    print(f"PREDICTION SUCCESSFUL")
    print("="*30)
    print(f"Detected Emotion: {emotion.upper()}")
    print(f"Confidence: {conf:.2f}%")
    print("="*30)
except Exception as e:
    print(f"Error: {e}")